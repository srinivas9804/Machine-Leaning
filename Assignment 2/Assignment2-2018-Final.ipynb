{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** SIVAKUMAR Srinivas\n",
    "\n",
    "**EID:** ssivakuma2\n",
    "\n",
    "**Kaggle Team Name:** Srinivas Sivakumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Assignment 2 - Sound Effects Retrieval\n",
    "Due date: November 5, 2018, 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final submission\n",
    "In this file, put the code that generates your final Kaggle submission. It will be used to verify that your Kaggle submission is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "random.seed(100)\n",
    "import csv\n",
    "from scipy import io\n",
    "import pickle\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAudio(info):\n",
    "    display(Audio(info['previews']['preview-lq-mp3']))\n",
    "\n",
    "def load_pickle(fname):\n",
    "    f = open(fname, 'rb')\n",
    "    out = pickle.load(f)\n",
    "    f.close()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags = load_pickle('sounds-data/train_tags.pickle3')\n",
    "train_mfccs = load_pickle('sounds-data/train_mfccs.pickle3')\n",
    "train_info = load_pickle('sounds-data/train_info.pickle3')\n",
    "\n",
    "valid_mfccs = load_pickle('sounds-data/val_mfccs.pickle3')\n",
    "valid_info = load_pickle('sounds-data/val_info.pickle3')\n",
    "valid_matches = load_pickle('sounds-data/val_matches.pickle3')\n",
    "\n",
    "test_mfccs = load_pickle('sounds-data/test_mfccs.pickle3')\n",
    "test_info = load_pickle('sounds-data/test_info.pickle3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_retr(testX, trainX):\n",
    "    # do retrieval using nearest neighbors\n",
    "    # for each entry in testX, find the top 10 closest entries in trainX using Euclidean distance\n",
    "    \n",
    "    test_retr = []  # retrieval list\n",
    "\n",
    "    # for each test document vector\n",
    "    for tX in testX:\n",
    "        # calculate the distance between tX and all training document vectors\n",
    "        # (using Euclidean distance)\n",
    "        if tX.ndim == 1:\n",
    "            ttX = tX.reshape((1,tX.shape[0]))\n",
    "        else:\n",
    "            ttX = tX;\n",
    "        D = metrics.pairwise_distances(ttX, trainX, metric='euclidean')\n",
    "        Df = D.flatten()\n",
    "        \n",
    "        # find the 10 with smallest distance\n",
    "        # (faster: bestmatches are the top-10, but not sorted yet)\n",
    "        bestmatches_unsorted = argpartition(Df, 10)[0:10]\n",
    "                \n",
    "        # now sort bestmatches\n",
    "        bestmatches_tmp = argsort(Df[bestmatches_unsorted])\n",
    "        bestmatches = bestmatches_unsorted[bestmatches_tmp]        \n",
    "        \n",
    "        # slow, since it sorts everything\n",
    "        #bestmatches = argsort(D.flatten())[0:10]\n",
    "    \n",
    "        # add to retrieval list\n",
    "        test_retr.append(bestmatches)\n",
    "\n",
    "    return test_retr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MAP(Ytrue, Ypred, K=10):\n",
    "    # calculate the mean average precision\n",
    "    # returns the MAP for the whole set, and the AP for each document\n",
    "    \n",
    "    AP = zeros(len(Ytrue))\n",
    "    # for each document\n",
    "    for j in range(len(Ytrue)):\n",
    "        Yt = Ytrue[j]\n",
    "        if not isinstance(Yt, ndarray):\n",
    "            Yt = array([Yt])\n",
    "        Yp = Ypred[j]\n",
    "        # calculate average precision @ K\n",
    "        nummatches = 0.\n",
    "        score = 0.\n",
    "        for i,y in enumerate(Yp[0:K]):\n",
    "            # if match at this level, calculate P\n",
    "            if any(y==Yt):\n",
    "                nummatches += 1.\n",
    "                P = nummatches / (i+1)\n",
    "                score += P\n",
    "        AP[j] = score / K #min(K, len(Yt))\n",
    "\n",
    "    # mean over all documents\n",
    "    MAP = mean(AP)\n",
    "    return (MAP, AP)\n",
    "\n",
    "# write a kaggle submission file for retrieval\n",
    "def write_csv_kaggle_retr_sub(fname, Yretr):\n",
    "    # header\n",
    "    tmp = [['Id', 'RetrievedDocuments']]\n",
    "    \n",
    "    # add ID numbers for each Y, and usage if necessary\n",
    "    for i in range(len(Yretr)):\n",
    "        y = Yretr[i]\n",
    "        ystr = [str(q) for q in y]\n",
    "        tmp2 = [str(i+1)]\n",
    "        tmp2.append(\" \".join(ystr))        \n",
    "        tmp.append(tmp2)\n",
    "        \n",
    "    # write CSV file\n",
    "    f = open(fname, 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tmp)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute delta MFCCs\n",
    "def compute_delta_mfccs(mfccs):\n",
    "    dmfccs = []\n",
    "    for m in mfccs:\n",
    "        tmp = m[1:] - m[0:-1]\n",
    "        dm = hstack((m[0:-1], tmp))\n",
    "        dmfccs.append(dm)\n",
    "    return dmfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dmfccs = compute_delta_mfccs(train_mfccs)\n",
    "test_dmfccs  = compute_delta_mfccs(test_mfccs)\n",
    "valid_dmfccs = compute_delta_mfccs(valid_mfccs)\n",
    "all_dmfccs = vstack(train_dmfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_transform(model, mfccs):\n",
    "    numwords = model.means_.shape[0]\n",
    "    bows = zeros((len(mfccs), numwords))\n",
    "    for i in range(len(mfccs)):\n",
    "        w = model.predict(mfccs[i])\n",
    "        bw = bincount(w, minlength=numwords)\n",
    "        bows[i,:] = bw\n",
    "    return bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_retr(testX, trainX):\n",
    "    # do retrieval using nearest neighbors\n",
    "    # for each entry in testX, find the top 10 closest entries in trainX using Manhattan distance\n",
    "    \n",
    "    test_retr = []  # retrieval list\n",
    "\n",
    "    # for each test document vector\n",
    "    for tX in testX:\n",
    "        # calculate the distance between tX and all training document vectors\n",
    "        # (using Euclidean distance)\n",
    "        if tX.ndim == 1:\n",
    "            ttX = tX.reshape((1,tX.shape[0]))\n",
    "        else:\n",
    "            ttX = tX;\n",
    "        D = metrics.pairwise_distances(ttX, trainX, metric='cityblock')\n",
    "        Df = D.flatten()\n",
    "        \n",
    "        # find the 10 with smallest distance\n",
    "        # (faster: bestmatches are the top-10, but not sorted yet)\n",
    "        bestmatches_unsorted = argpartition(Df, 10)[0:10]\n",
    "                \n",
    "        # now sort bestmatches\n",
    "        bestmatches_tmp = argsort(Df[bestmatches_unsorted])\n",
    "        bestmatches = bestmatches_unsorted[bestmatches_tmp]        \n",
    "        \n",
    "        # slow, since it sorts everything\n",
    "        #bestmatches = argsort(D.flatten())[0:10]\n",
    "    \n",
    "        # add to retrieval list\n",
    "        test_retr.append(bestmatches)\n",
    "\n",
    "    return test_retr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaReduction(features,components):\n",
    "    pca = decomposition.PCA(n_components=components)\n",
    "    result = pca.fit_transform(features)\n",
    "    return (pca,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 0\t time lapse 56.20184s\t ll change inf\n",
      "  Iteration 10\t time lapse 28.43504s\t ll change 0.01825\n",
      "  Iteration 20\t time lapse 29.54881s\t ll change 0.00669\n",
      "  Iteration 30\t time lapse 30.60758s\t ll change 0.00543\n",
      "  Iteration 40\t time lapse 31.03956s\t ll change 0.00197\n",
      "  Iteration 50\t time lapse 31.53767s\t ll change 0.00175\n",
      "  Iteration 60\t time lapse 33.83652s\t ll change 0.00192\n",
      "  Iteration 70\t time lapse 33.25508s\t ll change 0.00116\n",
      "Initialization converged: True\t time lapse 300.19637s\t ll -35.59491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "        means_init=None, n_components=500, n_init=1, precisions_init=None,\n",
       "        random_state=4487, reg_covar=1e-06, tol=0.001, verbose=2,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca,new_all_dmfccs = pcaReduction(all_dmfccs,8)\n",
    "new_train_dmfccs = []\n",
    "for j in range(len(train_dmfccs)):\n",
    "    new_train_dmfccs.append(pca.transform(train_dmfccs[j]))\n",
    "        \n",
    "new_valid_dmfccs = []\n",
    "for j in range(len(valid_dmfccs)):\n",
    "    new_valid_dmfccs.append(pca.transform(valid_dmfccs[j]))\n",
    "    \n",
    "new_test_dmfccs=[]\n",
    "for j in range(len(test_dmfccs)):\n",
    "        new_test_dmfccs.append(pca.transform(test_dmfccs[j]))\n",
    "\n",
    "\n",
    "gmm_diag = mixture.GaussianMixture(n_components=500, covariance_type='diag',\n",
    "                               random_state=4487, verbose=2)\n",
    "gmm_diag.fit(new_all_dmfccs[0::10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM using diagonal covariance and Manhattan distance, MAP = 0.15688126059485286\n"
     ]
    }
   ],
   "source": [
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "train_bow = bow_transform(gmm_diag, new_train_dmfccs)\n",
    "valid_bow = bow_transform(gmm_diag, new_valid_dmfccs)    \n",
    "train_Xtf = tf_trans.fit_transform(train_bow)\n",
    "valid_Xtf = tf_trans.transform(valid_bow)\n",
    "test_bow = bow_transform(gmm_diag, new_test_dmfccs)\n",
    "test_Xtf = tf_trans.transform(test_bow)\n",
    "\n",
    "val_retr  = nn_retr(valid_Xtf, train_Xtf)\n",
    "vMAP,vAP = calc_MAP(valid_matches, val_retr)\n",
    "print(\"GMM using diagonal covariance and Manhattan distance, MAP =\",vMAP)\n",
    "\n",
    "test_retr = nn_retr(test_Xtf, train_Xtf)\n",
    "write_csv_kaggle_retr_sub(\"final_submission.csv\", test_retr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
